[2023-03-29T21:25:22.834+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: my_dag.model_predict scheduled__2023-03-29T21:20:00+00:00 [queued]>
[2023-03-29T21:25:22.858+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: my_dag.model_predict scheduled__2023-03-29T21:20:00+00:00 [queued]>
[2023-03-29T21:25:22.860+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-29T21:25:22.862+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-29T21:25:22.864+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-29T21:25:22.893+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): model_predict> on 2023-03-29 21:20:00+00:00
[2023-03-29T21:25:22.904+0000] {standard_task_runner.py:55} INFO - Started process 1331 to run task
[2023-03-29T21:25:22.913+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'my_dag', 'model_predict', 'scheduled__2023-03-29T21:20:00+00:00', '--job-id', '526', '--raw', '--subdir', 'DAGS_FOLDER/test.py', '--cfg-path', '/tmp/tmpydyjwemq']
[2023-03-29T21:25:22.917+0000] {standard_task_runner.py:83} INFO - Job 526: Subtask model_predict
[2023-03-29T21:25:23.057+0000] {task_command.py:388} INFO - Running <TaskInstance: my_dag.model_predict scheduled__2023-03-29T21:20:00+00:00 [running]> on host 32688d23169d
[2023-03-29T21:25:23.323+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=my_dag
AIRFLOW_CTX_TASK_ID=model_predict
AIRFLOW_CTX_EXECUTION_DATE=2023-03-29T21:20:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-29T21:20:00+00:00
[2023-03-29T21:25:26.395+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/google/cloud/bigquery/table.py:1988: UserWarning: A progress bar was requested, but there was an error loading the tqdm library. Please install tqdm to use the progress bar functionality.
  create_bqstorage_client=create_bqstorage_client,

[2023-03-29T21:25:37.244+0000] {gbq.py:352} INFO - Total time taken 13.78 s.
Finished at 2023-03-29 21:25:37.
[2023-03-29T21:25:37.463+0000] {logging_mixin.py:137} INFO - [21:25:37] WARNING: ../src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.
[2023-03-29T21:25:38.316+0000] {logging_mixin.py:137} INFO -         age      sex  ...                 tax_filer_stat predictions-tax
0        15     Male  ...                         Single        0.000846
1        15     Male  ...                         Single        0.000319
2        15     Male  ...                         Single        0.000319
3        15     Male  ...                         Single        0.000146
4        15   Female  ...                         Single        0.000144
...     ...      ...  ...                            ...             ...
199517   90     Male  ...   Joint one under 65 & one 65+        0.064528
199518   90   Female  ...   Joint one under 65 & one 65+        0.033536
199519   90     Male  ...   Joint one under 65 & one 65+        0.125377
199520   90   Female  ...   Joint one under 65 & one 65+        0.096431
199521   90     Male  ...   Joint one under 65 & one 65+        0.236067

[199522 rows x 6 columns]
[2023-03-29T21:25:41.068+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas_gbq/load.py", line 136, in load_parquet
    project=billing_project,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/client.py", line 2675, in load_table_from_dataframe
    parquet_use_compliant_nested_type=True,
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/_pandas_helpers.py", line 586, in dataframe_to_parquet
    arrow_table = dataframe_to_arrow(dataframe, bq_schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/_pandas_helpers.py", line 529, in dataframe_to_arrow
    bq_to_arrow_array(get_column_or_index(dataframe, bq_field.name), bq_field)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/_pandas_helpers.py", line 290, in bq_to_arrow_array
    return pyarrow.Array.from_pandas(series, type=arrow_type)
  File "pyarrow/array.pxi", line 1037, in pyarrow.lib.Array.from_pandas
  File "pyarrow/array.pxi", line 313, in pyarrow.lib.array
  File "pyarrow/array.pxi", line 83, in pyarrow.lib._ndarray_to_array
  File "pyarrow/error.pxi", line 100, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: Rescaling Decimal128 value would cause data loss

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/test.py", line 147, in model_predict
    {'name':'predictions-tax','type': 'NUMERIC'}
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas_gbq/gbq.py", line 1205, in to_gbq
    billing_project=project_id,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas_gbq/gbq.py", line 599, in load_data
    billing_project=billing_project,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas_gbq/load.py", line 246, in load_chunks
    billing_project=billing_project,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas_gbq/load.py", line 141, in load_parquet
    ) from exc
pandas_gbq.exceptions.ConversionError: Could not convert DataFrame to Parquet.
[2023-03-29T21:25:41.090+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=my_dag, task_id=model_predict, execution_date=20230329T212000, start_date=20230329T212522, end_date=20230329T212541
[2023-03-29T21:25:41.118+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 526 for task model_predict (Could not convert DataFrame to Parquet.; 1331)
[2023-03-29T21:25:41.218+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-29T21:25:41.264+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
